{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPJmZcFzsk9s7ApDS979ihv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"eJAY9zXvOBVB"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import numpy as np\n","import cv2\n","import tensorflow as tf\n","import os\n","import random\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","from tqdm import tqdm\n","from tensorflow.keras.applications import MobileNetV2\n","print(os.getcwd())"],"metadata":{"id":"htAnTKdeOYBj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#paths\n","csv_path = 'drive/MyDrive/Colab Notebooks/IIIP/Testing chamber/seen.csv'\n","seen_folder_path = 'drive/MyDrive/Colab Notebooks/IIIP/Testing chamber/plantvillagesmall/seen'\n","image_classifier_model = 'drive/MyDrive/Colab Notebooks/IIIP/Testing chamber/Models/image_classifier.hdf5'\n","image_generator = 'drive/MyDrive/Colab Notebooks/IIIP/Testing chamber/Models/image_gen.hdf5'"],"metadata":{"id":"UFcArsTfOZXb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["folders = os.listdir(seen_folder_path)\n","print(folders)\n","\n","df = pd.read_csv(csv_path, header = None)\n","print(df)"],"metadata":{"id":"jbbUCM-6Oahg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# make dataset\n","seen_dataset = []\n","combined_label_dict = {}"],"metadata":{"id":"Ij1qRm3EOcX3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for index,row in df.iterrows():\n","  curr_folder_path = seen_folder_path + \"/\" + str(row[0])\n","  images = os.listdir(curr_folder_path)\n","  combined_label_dict[row[3]] = str(row[0])\n","  for i in tqdm(range(0,500)):\n","      select = random.choice(images)\n","      image = cv2.imread(os.path.join(curr_folder_path, select))\n","      image2 = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","      image2 = tf.image.resize(image2, (128, 128))\n","      seen_dataset.append((image2, row[3]))\n","      images.remove(select)\n","      if (len(images) == 0):\n","        break"],"metadata":{"id":"q7reCLnXOfvg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(seen_dataset))"],"metadata":{"id":"YnXi7dVyOyTP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.random.shuffle(plant_dataset_real)\n","\n","train, test = train_test_split(plant_dataset_real, test_size = 0.4)\n","\n","train_images = np.array([item[0] for item in train])\n","train_labels = np.array([item[1] for item in train])\n","\n","test_images = np.array([item[0] for item in test])\n","test_labels = np.array([item[1] for item in test])\n","\n","print(\"Train length: \", str(len(train_images)))\n","print(\"Test length: \", str(len(test_images)))\n","\n","train_images = tf.image.resize(train_images, (128, 128))\n","train_labels = tf.one_hot(train_labels, depth=6)\n","\n","test_images = tf.image.resize(test_images, (128, 128))\n","test_labels = tf.one_hot(test_labels, depth=6)\n","\n","print(train_images.shape)\n","print(test_images.shape)"],"metadata":{"id":"uh2x2IdiOt6u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_input = tf.keras.layers.Input(shape=(128,128,3))\n","\n","mobilenet = MobileNetV2(include_top=False, input_tensor=image_input)\n","mobilenet.trainable = True\n","\n","image_classfier = tf.keras.Sequential([\n","  tf.keras.layers.Input(shape = (128,128,3)),\n","  mobilenet,\n","  tf.keras.layers.Flatten(),\n","  tf.keras.layers.Dense(512, activation='relu'),\n","  tf.keras.layers.Dense(6,activation='softmax')\n","])\n","\n","image_classfier.compile(\n","  optimizer=tf.keras.optimizers.Adam(learning_rate = 0.0001),\n","  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n","  metrics=['accuracy'])\n","image_classfier.summary()"],"metadata":{"id":"JXBA-RAfOlXo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train the model\n","history = model_fit = plant_image_classfierimage_real.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n","\n","# evaluate model\n","_, train_acc = image_classfier.evaluate(train_images, train_labels)\n","_, test_acc = image_classfier.evaluate(test_images, test_labels )\n","\n","print(f'\\nTrain accuracy: {train_acc:.0%}')\n","print(f'Test accuracy: {test_acc:.0%}')\n","\n","image_classfier.save(image_classifier_model)\n"],"metadata":{"id":"nVv6B4EMO55Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras import layers\n","latent_dim = 100\n","classes = 6\n","def define_generator():\n","    noise = layers.Input(shape=(latent_dim,))\n","    label = layers.Input(shape=(1,))\n","\n","    label_embedding = layers.Flatten()(layers.Embedding(classes, latent_dim)(label))\n","    model_input = layers.Concatenate()([noise, label_embedding])\n","\n","    x = layers.Dense(512 * 4 * 4)(model_input)\n","\n","    x = layers.Reshape((4, 4, 512))(x)\n","    x = layers.BatchNormalization(momentum=0.9)(x)\n","    x = layers.LeakyReLU(0.1)(x)\n","\n","    x = layers.Conv2DTranspose(64 * 8, kernel_size=4, strides=2, padding='same', kernel_initializer=tf.keras.initializers.RandomNormal(), name='conv_transpose_1')(x)\n","    x = layers.BatchNormalization(momentum=0.1, name='bn_1')(x)\n","    x = layers.LeakyReLU(name='leaky_relu_1')(x)\n","\n","    x = layers.Conv2DTranspose(64 * 4, kernel_size=4, strides=2, padding='same', kernel_initializer=tf.keras.initializers.RandomNormal(), name='conv_transpose_2')(x)\n","    x = layers.BatchNormalization(momentum=0.1, name='bn_2')(x)\n","    x = layers.LeakyReLU(name='leaky_relu_2')(x)\n","\n","    x = layers.Conv2DTranspose(64 * 2, kernel_size=4, strides=2, padding='same', kernel_initializer=tf.keras.initializers.RandomNormal(), name='conv_transpose_3')(x)\n","    x = layers.BatchNormalization(momentum=0.1, name='bn_3')(x)\n","    x = layers.LeakyReLU(name='leaky_relu_3')(x)\n","\n","    x = layers.Conv2DTranspose(64 * 1, kernel_size=4, strides=2, padding='same', kernel_initializer=tf.keras.initializers.RandomNormal(), name='conv_transpose_4')(x)\n","    x = layers.BatchNormalization(momentum=0.1, name='bn_4')(x)\n","    x = layers.LeakyReLU(name='leaky_relu_4')(x)\n","\n","    out_layer = layers.Conv2DTranspose(3, 4, 2,padding='same', kernel_initializer=tf.keras.initializers.RandomNormal(),  activation='tanh', name='conv_transpose_6')(x)\n","\n","   # define model\n","    model = tf.keras.Model([noise, label], out_layer)\n","    return model\n","\n","image_gen = define_generator()\n","image_gen.load_weights(image_generator)\n","print(image_gen.summary())"],"metadata":{"id":"_XlTm3bGPUNz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fake_dataset = []\n","fake_label = []\n","seed = tf.random.normal([20, latent_dim])\n","seed.dtype\n","for i in range(6):\n","   curr_label = []\n","   for j in range(20):\n","        curr_label.append(i)\n","        fake_label.append(i)\n","   curr_label = tf.convert_to_tensor(curr_label)\n","   images = image_gen([seed, curr_label], training=False)\n","   for k in range(images.shape[0]):\n","      pred = (images[i, :, :, :] + 1 ) * 127.5\n","      pred = np.array(pred)\n","      fake_dataset.append(pred)\n","\n","print(len(fake_dataset))"],"metadata":{"id":"es6_EJJcPc8j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["real_dataset=[]\n","real_label=[]\n","for index,row in df.iterrows():\n","  curr_folder_path = seen_folder_path + \"/\" + str(row[0])\n","  images = os.listdir(curr_folder_path)\n","  combined_label_dict[row[3]] = str(row[0])\n","  for i in tqdm(range(0,20)):\n","      image = cv2.imread(os.path.join(curr_folder_path, select))\n","      image2 = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","      image2 = tf.image.resize(image2, (128, 128))\n","      real_dataset.append(image2)\n","      real_label.append(row[3])"],"metadata":{"id":"f4kDERPQPorb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for n in range(1,7):\n","    fake_class_images = []\n","    real_class_images = []\n","    fake_labels = []\n","    real_labels = []\n","    for i in range((n*20)-20, (n*20)):\n","        fake_class_embeddings.append(fake_dataset[i])\n","    for i in range((n*20)-20, (n*20)):\n","        real_class_embeddings.append(real_dataset[i])\n","        real_labels.append(eval_labels_real[i])\n","    for i in range(20):\n","        fake_overall_labels.append(n-1)\n","        fake_labels.append(n-1)\n","\n","    fake_class_images = np.array(fake_class_images)\n","    real_class_images = np.array(real_class_images)\n","\n","    fake_labels = tf.one_hot(np.array(fake_labels), depth=6)\n","    real_labels = tf.one_hot(np.array(real_labels), depth=6)\n","\n","\n","    print(\"=======================================\")\n","    print(\"Class-wise Accuracy: Class \" + str(n))\n","    loss, racc = embed_classifier.evaluate(real_class_images, real_labels)\n","    loss, facc = embed_classifier.evaluate(fake_class_images, fake_labels)\n","    print(\"Real class Accuracy: \" + str(racc))\n","    print(\"Fake class Accuracy: \" + str(facc))\n","\n","print(\"=======================================\")\n","print(\"Overall Accuracy:\")\n","fake_overall_labels = tf.one_hot(np.array(fake_overall_labels), depth=6)\n","eval_labels_real = tf.one_hot(np.array(eval_labels_real), depth=6)\n","\n","loss, racc = embed_classifier.evaluate(real_embeddings, eval_labels_real)\n","loss, facc = embed_classifier.evaluate(fake_embeddings, fake_overall_labels)\n","print(\"Real Overall Accuracy: \" + str(racc))\n","print(\"Fake Overall Accuracy: \" + str(facc))"],"metadata":{"id":"u5uFQ3BVQJIg"},"execution_count":null,"outputs":[]}]}